name: Monitor URL Changes

on:
  workflow_dispatch:
  push:
    branches: [ main ]
  schedule:
    - cron: '0 23,0-13 * * *'

permissions:
  contents: write

jobs:
  check_url_changes:
    runs-on: ubuntu-latest
    env:
      SCTKEY: ${{ secrets.SCTKEY }}
      WEBHOOK_URLS: ${{ secrets.WEBHOOK_URLS || '[]' }}
      CONFIG_JSON: |
        {
          "urls": {
            "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=2331": "杭州地铁招标计划发布",
            "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=2332": "杭州地铁招标预公示",
            "https://ztb.cxjw.hangzhou.gov.cn:8092/jyxxjhfb": "杭州建设项目 招标计划发布"
          },
          "selectors": {
            "main_content": ["div.main-content", "section.content"],
            "remove_elements": ["script", "style", "footer"]
          }
        }

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install \
            aiohttp==3.9.3 \
            aiohttp-retry==2.8.3 \
            beautifulsoup4==4.12.2 \
            lxml==5.2.1

      - name: Async check and notify
        run: |
          python - << "EOF"
          import os
          import json
          import hashlib
          import asyncio
          from aiohttp import ClientSession, TCPConnector
          from aiohttp_retry import RetryClient, ExponentialRetry
          from bs4 import BeautifulSoup

          class AsyncMonitor:
              def __init__(self):
                  self.config = json.loads(os.getenv("CONFIG_JSON"))
                  self.urls = list(self.config["urls"].keys())
                  self.state_file = "url_state.json"
                  self.connector = TCPConnector(limit=10)
                  self.retry_options = ExponentialRetry(
                      attempts=5,
                      start_timeout=1,
                      max_timeout=10,
                      exceptions={Exception}
                  )

              async def fetch_hash(self, session, url):
                  try:
                      async with session.get(url) as response:
                          html = await response.text()
                          
                          # 流式哈希计算
                          hasher = hashlib.sha256()
                          async for chunk in response.content.iter_chunked(4096):
                              hasher.update(chunk)
                          
                          soup = BeautifulSoup(html, 'lxml')
                          self.clean_html(soup)
                          return url, hasher.hexdigest()
                  except Exception as e:
                      print(f"Error fetching {url}: {str(e)}")
                      return url, None

              def clean_html(self, soup):
                  # 高效清理策略
                  for tag in self.config["selectors"]["remove_elements"]:
                      for element in soup.find_all(tag):
                          element.decompose()

                  # 精确内容定位
                  for selector in self.config["selectors"]["main_content"]:
                      if content := soup.select_one(selector):
                          soup = content
                          break
                  return soup

              async def check_urls(self):
                  async with RetryClient(
                      connector=self.connector,
                      retry_options=self.retry_options
                  ) as session:
                      tasks = [self.fetch_hash(session, url) for url in self.urls]
                      return await asyncio.gather(*tasks)

              async def notify_all(self, changes):
                  if not changes:
                      return
                  
                  # 合并通知内容
                  markdown_content = "### 更新通知\n" + "\n".join(
                      f"[{self.config['urls'][url]}]({url})" 
                      for url in changes
                  )

                  # 异步发送所有通知
                  await asyncio.gather(
                      self.send_serverchan(markdown_content),
                      self.send_wechatwork(markdown_content)
                  )

              async def send_serverchan(self, content):
                  if sctkey := os.getenv("SCTKEY"):
                      async with ClientSession() as session:
                          await session.post(
                              f"https://sctapi.ftqq.com/{sctkey}.send",
                              json={'title': '内容更新', 'desp': content}
                          )

              async def send_wechatwork(self, content):
                  if webhooks := json.loads(os.getenv("WEBHOOK_URLS", "[]")):
                      async with ClientSession() as session:
                          tasks = [
                              session.post(
                                  wh["url"],
                                  json={"msgtype": "markdown", "markdown": {"content": content}}
                              )
                              for wh in webhooks
                          ]
                          await asyncio.gather(*tasks)

              def load_state(self):
                  try:
                      with open(self.state_file) as f:
                          return json.load(f)
                  except (FileNotFoundError, json.JSONDecodeError):
                      return {}

              def save_state(self, state):
                  with open(self.state_file, 'w') as f:
                      json.dump(state, f, indent=2)

              async def run(self):
                  previous_state = self.load_state()
                  current_state = {}
                  results = await self.check_urls()
                  
                  # 识别变更项
                  changes = [
                      url for url, hash_val in results 
                      if hash_val and previous_state.get(url) != hash_val
                  ]
                  current_state.update({url: hash_val for url, hash_val in results if hash_val})

                  if changes:
                      print(f"检测到 {len(changes)} 项更新")
                      await self.notify_all(changes)
                      self.save_state(current_state)
                  else:
                      print("未检测到变化")

          if __name__ == "__main__":
              monitor = AsyncMonitor()
              asyncio.run(monitor.run())
          EOF

      - name: Commit and push state file
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          if git diff --quiet url_state.json; then
            echo "No changes detected."
          else
            git add url_state.json
            git commit -m "Update URL states [skip ci]"
            git push
          fi
