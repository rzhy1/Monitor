name: Monitor URL Changes

on:
  workflow_dispatch:
  push:
    branches: [ main ]
  schedule:
    - cron: '0 23,0-13 * * *'

permissions:
  contents: write

jobs:
  check_url_changes:
    runs-on: ubuntu-latest
    env:
      SCTKEY: ${{ secrets.SCTKEY }}
      WEBHOOK_URLS: ${{ secrets.WEBHOOK_URLS || '[]' }}
      CONFIG_JSON: |
        {
          "urls": {
            "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=2331": "杭州地铁招标计划发布",
            "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=2332": "杭州地铁招标预公示",
            "https://ztb.cxjw.hangzhou.gov.cn:8092/jyxxjhfb": "杭州建设项目 招标计划发布"
          },
          "selectors": {
            "main_content": ["div.main-content", "section.content"],
            "remove_elements": ["script", "style", "footer"]
          }
        }

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install \
            aiohttp==3.9.3 \
            aiohttp-retry==2.8.3 \
            beautifulsoup4==4.12.2 \
            lxml==5.2.1

      - name: Async check and notify
        run: |
          python - << "EOF"
          import os
          import json
          import hashlib
          import asyncio
          from aiohttp import ClientSession, TCPConnector, ClientTimeout
          from aiohttp_retry import RetryClient, ExponentialRetry
          from bs4 import BeautifulSoup

          class AsyncMonitor:
              def __init__(self):
                  self.config = json.loads(os.getenv("CONFIG_JSON"))
                  self.urls = list(self.config["urls"].keys())
                  self.state_file = "url_state.json"
                  self.timeout = ClientTimeout(total=15)
                  self.connector = TCPConnector(limit=10, ssl=False)
                  self.retry_options = ExponentialRetry(
                      attempts=3,
                      start_timeout=2,
                      max_timeout=10,
                      exceptions={asyncio.TimeoutError}
                  )

              async def fetch_hash(self, session, url):
                  try:
                      async with session.get(url, timeout=self.timeout) as response:
                          # 流式哈希计算
                          hasher = hashlib.sha256()
                          async for chunk in response.content.iter_chunked(4096):
                              hasher.update(chunk)
                          
                          html = await response.text()
                          soup = BeautifulSoup(html, 'lxml')
                          cleaned = self.clean_html(soup)
                          return url, hasher.hexdigest()
                  except Exception as e:
                      print(f"Error fetching {url}: {type(e).__name__} - {str(e)}")
                      return url, None

              def clean_html(self, soup):
                  # 高效清理策略
                  for tag in self.config["selectors"]["remove_elements"]:
                      for element in soup.find_all(tag):
                          element.decompose()

                  # 精确内容定位
                  for selector in self.config["selectors"]["main_content"]:
                      if content := soup.select_one(selector):
                          return content
                  return soup

              async def check_urls(self):
                  async with RetryClient(
                      connector=self.connector,
                      retry_options=self.retry_options,
                      timeout=self.timeout
                  ) as session:
                      tasks = [self.fetch_hash(session, url) for url in self.urls]
                      return await asyncio.gather(*tasks)

              # 保持其他方法不变...

          if __name__ == "__main__":
              monitor = AsyncMonitor()
              asyncio.run(monitor.run())
          EOF

      - name: Commit and push state file
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          if git diff --quiet url_state.json; then
            echo "No changes detected."
          else
            git add url_state.json
            git commit -m "Update URL states [skip ci]"
            git push
          fi
