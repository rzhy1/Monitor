name: Monitor URL Changes

on:
  workflow_dispatch:
  push:
    branches: [ main ]
  schedule:
    - cron: '0 23,0-13 * * *'

permissions:
  contents: write

jobs:
  check_url_changes:
    runs-on: ubuntu-latest
    env:
      WEBHOOK_URLS: ${{ secrets.WEBHOOK_URLS || '[]' }}
      CHECK_URLS: |
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E8%BD%A6%E8%BE%86%E6%AE%B5&status=5&channelId=2331
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=2331
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=2332
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3508
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3509
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3510
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3511
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3512
        https://github.com/rzhy1/aria2-static-build/blob/main/.github/workflows/build_and_release.yml
      URL_DESCRIPTIONS: |
        {"https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E8%BD%A6%E8%BE%86%E6%AE%B5&status=5&channelId=2331": "车辆段招标计划发布",
        "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=2331": "杭州地铁招标计划发布",
         "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=2332": "杭州地铁招标预公示",
         "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3508": "杭州地铁特别提醒项目",
         "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3509": "杭州地铁招标核准项目",
         "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3510": "杭州地铁招标文件公示",
         "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3511": "杭州地铁中标公示",
         "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3512": "杭州地铁中标结果",
         "https://github.com/rzhy1/aria2-static-build/blob/main/.github/workflows/build_and_release.yml": "测试专用"}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install \
            requests==2.31.0 \
            beautifulsoup4==4.12.2 \
            urllib3==2.0.7

      - name: Check and notify
        run: |
          python - << "EOF"
          import os
          import json
          import hashlib
          import time
          import re
          import requests
          from bs4 import BeautifulSoup, Comment
          from requests.adapters import HTTPAdapter
          from urllib3.util.retry import Retry

          # 常量配置
          USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
          STATE_FILE = "url_state.json"
          CLEAN_TAGS = ['script', 'style', 'nav', 'footer', 'aside', 'header']
          CONTENT_SELECTORS = [
              ('div', {'class': 'menu menu_time'}),
              ('div', {'id': 'main-content'}),
              ('section', {'role': 'main'}),
              ('article', {}),      # 新增通用文章区域
              ('main', {}),         # 新增主内容区
              ('div', {'class': 'content'})  # 新增通用内容div
          ]

          class Monitor:
              def __init__(self):
                  self.session = self.create_session()
                  self.url_descriptions = json.loads(os.getenv("URL_DESCRIPTIONS"))
                  self.check_urls = [u.strip() for u in os.getenv("CHECK_URLS").splitlines() if u.strip()]
                  self.base_url = "https://ztb.cxjw.hangzhou.gov.cn:8092"

              def create_session(self):
                  """创建带重试机制的会话"""
                  session = requests.Session()
                  retry = Retry(
                      total=3,
                      backoff_factor=1,
                      status_forcelist=[429, 500, 502, 503, 504],
                      allowed_methods=['GET']
                  )
                  adapter = HTTPAdapter(max_retries=retry)
                  session.mount('https://', adapter)
                  session.mount('http://', adapter)
                  return session

              def clean_content(self, html):
                  """清理HTML内容"""
                  soup = BeautifulSoup(html, 'html.parser')
                  
                  # 移除干扰元素
                  for tag in CLEAN_TAGS:
                      for element in soup.find_all(tag):
                          element.decompose()
                  
                  # 移除注释
                  for comment in soup.find_all(string=lambda t: isinstance(t, Comment)):
                      comment.extract()

                  # 定位主要内容
                  main_content = None
                  for selector in CONTENT_SELECTORS:
                      main_content = soup.find(*selector)
                      if main_content: break
                  return main_content or soup

              def extract_project_titles(self, html, current_url):
                  """提取项目标题和链接"""
                  soup = BeautifulSoup(html, 'html.parser')
                  titles_with_links = []
                  
                  # 查找所有包含项目标题的div
                  for div in soup.find_all('div', class_='menu menu_time'):
                      h3 = div.find('h3')
                      if h3:
                          # 提取纯文本内容，去除HTML标签
                          title_text = h3.get_text(strip=True)
                          
                          # 尝试从onclick属性中提取链接
                          onclick = div.get('onclick', '')
                          detail_url = None
                          
                          if onclick and 'window.open' in onclick:
                              # 使用正则表达式提取URL
                              match = re.search(r"window\.open\('([^']+)'\)", onclick)
                              if match:
                                  detail_path = match.group(1)
                                  # 构建完整URL
                                  if detail_path.startswith('/'):
                                      detail_url = f"{self.base_url}{detail_path}"
                                  else:
                                      detail_url = detail_path
                          
                          # 如果没有提取到详细链接，使用当前页面URL
                          if not detail_url:
                              detail_url = current_url
                          
                          titles_with_links.append((title_text, detail_url))
                  
                  return titles_with_links

              def get_content_hash(self, url):
                  """获取内容哈希值"""
                  try:
                      response = self.session.get(
                          url,
                          headers={'User-Agent': USER_AGENT, 'Cache-Control': 'no-cache'},
                          timeout=10
                      )
                      response.raise_for_status()
                      
                      cleaned = self.clean_content(response.text)
                      text = cleaned.get_text('\n', strip=True)
                      return hashlib.sha256(text.encode()).hexdigest(), response.text
                  except Exception as e:
                      print(f"[ERROR] 检查 {url} 失败: {str(e)}")
                      return None, None

              def load_state(self):
                  """加载历史状态"""
                  try:
                      with open(STATE_FILE, 'r') as f:
                          return json.load(f)
                  except (FileNotFoundError, json.JSONDecodeError):
                      return {}

              def save_state(self, state):
                  """保存当前状态"""
                  try:
                      with open(STATE_FILE, 'w') as f:
                          json.dump(state, f, indent=2)
                  except IOError as e:
                      print(f"[ERROR] 保存状态失败: {str(e)}")

              def send_notifications(self, changed_urls, url_titles_map):
                  """发送通知"""
                  # 准备消息内容
                  markdown_msg = []
                  for url in changed_urls:
                      desc = self.url_descriptions.get(url, "未知更新")
                      titles_with_links = url_titles_map.get(url, [])
                      
                      if titles_with_links:
                          # 为每个标题创建带链接的格式
                          title_links = []
                          for title, link in titles_with_links:
                              title_links.append(f"[{title}]({link})")
                          
                          title_list = "\n".join([f"• {link}" for link in title_links])
                          # 保留查看详情链接，指向原监控页面
                          markdown_msg.append(f"**{desc}**\n{title_list}\n[查看详情]({url})")
                      else:
                          markdown_msg.append(f"**{desc}**\n[查看详情]({url})")

                  # 企业微信通知
                  if webhooks := json.loads(os.getenv("WEBHOOK_URLS", "[]")):
                      self._send_wechatwork(markdown_msg, webhooks)

              def _send_wechatwork(self, items, webhooks):
                  """发送企业微信通知"""
                  for webhook in webhooks:
                      try:
                          resp = self.session.post(
                              webhook['url'],
                              json={
                                  "msgtype": "markdown",
                                  "markdown": {
                                      "content": "### 更新通知\n" + "\n\n".join(items)
                                  }
                              },
                              timeout=15
                          )
                          if resp.status_code == 200:
                              print(f"企业微信通知成功: {webhook.get('note')}")
                          else:
                              print(f"[ERROR] 企业微信通知失败: {resp.status_code}")
                      except Exception as e:
                          print(f"[ERROR] 企业微信通知异常: {str(e)}")

              def run(self):
                  """主执行流程"""
                  previous_state = self.load_state()
                  current_state = {}
                  changed_urls = []
                  url_titles_map = {}  # 存储每个URL对应的项目标题和链接

                  for url in self.check_urls:
                      result = self.get_content_hash(url)
                      if result[0] is not None:
                          current_hash, html_content = result
                          current_state[url] = current_hash
                          
                          # 提取项目标题和链接
                          titles_with_links = self.extract_project_titles(html_content, url)
                          if titles_with_links:
                              url_titles_map[url] = titles_with_links
                          
                          if previous_state.get(url) != current_hash:
                              changed_urls.append(url)
                      time.sleep(1)  # 基础请求间隔

                  if changed_urls:
                      print(f"检测到 {len(changed_urls)} 项更新")
                      for url in changed_urls:
                          desc = self.url_descriptions.get(url, "未知更新")
                          titles_with_links = url_titles_map.get(url, [])
                          print(f"⭐ {desc}: {url}")
                          if titles_with_links:
                              for title, link in titles_with_links:
                                  print(f"  项目标题: {title} -> {link}")
                      
                      self.send_notifications(changed_urls, url_titles_map)
                      self.save_state(current_state)
                  else:
                      print("未检测到变化")

          if __name__ == "__main__":
              Monitor().run()
          EOF

      - name: Commit and push state file
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          if git diff --quiet url_state.json; then
            echo "No changes detected in url_state.json."
          else
            echo "Changes detected in url_state.json, preparing to commit..."
            git add url_state.json
            git commit -m "Update URL states [skip ci]" || echo "No changes to commit."
            git push origin HEAD || echo "Push failed, please check permissions or network issues."
            echo "状态文件已更新并提交"
          fi
