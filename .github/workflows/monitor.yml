name: Monitor URL Changes

on:
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - '.github/workflows/monitor.yml'
      - 'url_state.json'
  schedule:
    - cron: '0 23,0-13 * * *'  # æ¯å¤© 23:00ã€0-13ç‚¹æ¯å°æ—¶è¿è¡Œ

permissions:
  contents: write

jobs:
  check_url_changes:
    runs-on: ubuntu-latest
    env:
      WEBHOOK_URLS: ${{ secrets.WEBHOOK_URLS }}
      CHECK_URLS: |
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=2331
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=2332
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3508
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3509
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3510
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3511
        https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3512
        https://github.com/rzhy1/aria2-static-build/blob/main/.github/workflows/build_and_release.yml
      URL_DESCRIPTIONS: |
        {"https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=2331": "æ­å·åœ°é“æ‹›æ ‡è®¡åˆ’å‘å¸ƒ",
         "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=2332": "æ­å·åœ°é“æ‹›æ ‡é¢„å…¬ç¤º",
         "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3508": "æ­å·åœ°é“ç‰¹åˆ«æé†’é¡¹ç›®",
         "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3509": "æ­å·åœ°é“æ‹›æ ‡æ ¸å‡†é¡¹ç›®",
         "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3510": "æ­å·åœ°é“æ‹›æ ‡æ–‡ä»¶å…¬ç¤º",
         "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3511": "æ­å·åœ°é“ä¸­æ ‡å…¬ç¤º",
         "https://ztb.cxjw.hangzhou.gov.cn:8092/search/queryContents.jhtml?titleOrCode=%E5%9F%8E%E5%B8%82%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A&status=5&channelId=3512": "æ­å·åœ°é“ä¸­æ ‡ç»“æœ",
         "https://github.com/rzhy1/aria2-static-build/blob/main/.github/workflows/build_and_release.yml": "æµ‹è¯•ä¸“ç”¨"}

    steps:
      - uses: actions/checkout@v6

      - uses: actions/setup-python@v6
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 urllib3

      - name: Check and notify
        run: |
          python - << "EOF"
          import os, json, hashlib, time, re, requests
          from bs4 import BeautifulSoup
          from requests.adapters import HTTPAdapter
          from urllib3.util.retry import Retry

          USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
          STATE_FILE = "url_state.json"

          class Monitor:
              def __init__(self):
                  self.session = self.create_session()
                  self.url_descriptions = json.loads(os.getenv("URL_DESCRIPTIONS"))
                  self.check_urls = [u.strip() for u in os.getenv("CHECK_URLS").splitlines() if u.strip()]
                  self.base_url = "https://ztb.cxjw.hangzhou.gov.cn:8092"

              def create_session(self):
                  session = requests.Session()
                  retry = Retry(
                      total=3,
                      backoff_factor=1,
                      status_forcelist=[429, 500, 502, 503, 504],
                      allowed_methods=['GET']
                  )
                  adapter = HTTPAdapter(max_retries=retry)
                  session.mount('https', adapter)
                  session.mount('http', adapter)
                  return session

              def extract_project_titles(self, html, current_url):
                  soup = BeautifulSoup(html, 'html.parser')
                  titles_with_links = []

                  selectors = [
                      'div.menu.menu_time',
                      'div.list > div',
                      '.listWrap .list > div'
                  ]

                  menu_divs = []
                  for selector in selectors:
                      menu_divs = soup.select(selector)
                      if menu_divs:
                          break

                  if not menu_divs:
                      menu_divs = soup.find_all('div', onclick=lambda x: x and 'window.open' in x)

                  for div in menu_divs:
                      title_element = div.find('h3') or div.find('a') or div
                      title_text = title_element.get_text(strip=True)
                      if not title_text or len(title_text) < 5:
                          continue

                      onclick = div.get('onclick', '')
                      detail_url = None
                      if onclick and 'window.open' in onclick:
                          match = re.search(r"window\.open\s*\(\s*['\"]([^'\"]+)['\"]", onclick)
                          if match:
                              detail_path = match.group(1)
                              detail_url = f"{self.base_url}{detail_path}" if detail_path.startswith('/') else detail_path
                      if not detail_url:
                          detail_url = current_url

                      titles_with_links.append((title_text, detail_url))
                  return titles_with_links

              def get_content_hash(self, url):
                  try:
                      response = self.session.get(url, headers={'User-Agent': USER_AGENT}, timeout=10)
                      response.raise_for_status()
                      titles_with_links = self.extract_project_titles(response.text, url)
                      sorted_titles = sorted([title for title, link in titles_with_links])
                      content_for_hash = "\n".join(sorted_titles)
                      return hashlib.sha256(content_for_hash.encode()).hexdigest(), response.text
                  except Exception as e:
                      print(f"[ERROR] æ£€æŸ¥ {url} å¤±è´¥: {str(e)}")
                      return None, None

              def load_state(self):
                  try:
                      with open(STATE_FILE, 'r') as f:
                          state = json.load(f)
                  except (FileNotFoundError, json.JSONDecodeError):
                      state = {}
                  for url in self.check_urls:
                      if url not in state:
                          state[url] = {"hash": None, "titles": []}
                      elif isinstance(state[url], str):
                          state[url] = {"hash": state[url], "titles": []}
                  return state

              def save_state(self, state):
                  try:
                      with open(STATE_FILE, 'w') as f:
                          json.dump(state, f, indent=2)
                  except IOError as e:
                      print(f"[ERROR] ä¿å­˜çŠ¶æ€å¤±è´¥: {str(e)}")

              def get_new_titles(self, current_titles, previous_titles):
                  previous_set = set(previous_titles)
                  new_titles = [title for title in current_titles if title[0] not in previous_set]
                  return new_titles

              def send_notifications(self, changed_urls, new_titles_map):
                  markdown_msgs = []
                  for url in changed_urls:
                      desc = self.url_descriptions.get(url, "æœªçŸ¥æ›´æ–°")
                      new_titles = new_titles_map.get(url, [])
                      if new_titles:
                          title_links = [f"[{title}]({link})" for title, link in new_titles]
                          title_list = "\n".join([f"ğŸ”´ {link}" for link in title_links])
                          message = f"**{desc}**\n{title_list}\n[ğŸ”µæŸ¥çœ‹è¯¦æƒ…]({url})"
                          if len(message) > 4000:
                              parts = self.split_long_message(message)
                              markdown_msgs.extend(parts)
                          else:
                              markdown_msgs.append(message)
                      else:
                          message = f"**{desc}**\né¡µé¢å†…å®¹æœ‰å˜åŒ–ï¼Œä½†æ²¡æœ‰æ£€æµ‹åˆ°æ–°å¢é¡¹ç›®\n[ğŸ”µæŸ¥çœ‹è¯¦æƒ…]({url})"
                          markdown_msgs.append(message)

                  webhook_urls = os.getenv("WEBHOOK_URLS")
                  if webhook_urls:
                      try:
                          webhooks = json.loads(webhook_urls)
                          self._send_wechatwork(markdown_msgs, webhooks)
                      except json.JSONDecodeError:
                          print("WEBHOOK_URLS æ ¼å¼é”™è¯¯")
                  else:
                      print("æœªè®¾ç½® WEBHOOK_URLSï¼Œè·³è¿‡é€šçŸ¥å‘é€")

              def split_long_message(self, message, max_length=4000):
                  parts = []
                  while len(message) > max_length:
                      split_pos = message.rfind('\n', 0, max_length)
                      if split_pos == -1:
                          split_pos = max_length
                      parts.append(message[:split_pos])
                      message = message[split_pos:]
                  if message:
                      parts.append(message)
                  return parts

              def _send_wechatwork(self, items, webhooks):
                  for webhook in webhooks:
                      for i, item in enumerate(items):
                          data = {"msgtype": "markdown", "markdown": {"content": item}}
                          try:
                              resp = self.session.post(webhook['url'], json=data, timeout=15)
                              if resp.status_code == 200 and resp.json().get('errcode') == 0:
                                  print(f"âœ… ç¬¬ {i+1} æ¡æ¶ˆæ¯å‘é€æˆåŠŸ")
                              else:
                                  print(f"âŒ ç¬¬ {i+1} æ¡æ¶ˆæ¯å‘é€å¤±è´¥")
                          except Exception as e:
                              print(f"[ERROR] ä¼ä¸šå¾®ä¿¡é€šçŸ¥å¼‚å¸¸: {str(e)}")
                          time.sleep(1)

              def run(self):
                  previous_state = self.load_state()
                  current_state = {}
                  changed_urls = []
                  new_titles_map = {}

                  for url in self.check_urls:
                      print(f"\næ£€æŸ¥ URL: {url}")
                      current_hash, html_content = self.get_content_hash(url)
                      if current_hash:
                          current_titles = self.extract_project_titles(html_content, url)
                          previous_titles = previous_state.get(url, {}).get("titles", [])
                          new_titles = self.get_new_titles(current_titles, previous_titles)
                          current_state[url] = {"hash": current_hash, "titles": [t[0] for t in current_titles]}
                          previous_hash = previous_state.get(url, {}).get("hash")
                          if new_titles or previous_hash != current_hash:
                              changed_urls.append(url)
                              new_titles_map[url] = new_titles
                              print(f"URL {url} æ£€æµ‹åˆ°å˜åŒ–: æ–°å¢ {len(new_titles)} ä¸ª, å“ˆå¸Œå˜åŒ–={previous_hash != current_hash}")
                          else:
                              print(f"URL {url} æœªæ£€æµ‹åˆ°å˜åŒ–")
                      time.sleep(1)

                  if changed_urls:
                      self.send_notifications(changed_urls, new_titles_map)
                      self.save_state(current_state)
                  else:
                      print("æœªæ£€æµ‹åˆ°ä»»ä½•å˜åŒ–")

          if __name__ == "__main__":
              Monitor().run()
          EOF

      - name: Commit and push state file
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          if git diff --quiet url_state.json; then
            echo "No changes detected in url_state.json."
          else
            git add url_state.json
            git commit -m "Update URL states [skip ci]" || echo "No changes to commit."
            git push origin HEAD || echo "Push failed"
            echo "çŠ¶æ€æ–‡ä»¶å·²æ›´æ–°å¹¶æäº¤"
